{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "fcrYstR94FJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import os"
      ],
      "metadata": {
        "id": "JvQaS37I4Gy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SAVE_FREQUENCY = 50 # Save 3 consecutive frames every nth step\n",
        "\n",
        "\n",
        "\n",
        "# Convert color to grayscale\n",
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "# Turn discrete scalar action into continuous\n",
        "def format_action(num):\n",
        "  if num == 0:\n",
        "    action = [-1, 0, 0]\n",
        "  elif num == 1:\n",
        "    action = [1, 0, 0]\n",
        "  elif num == 2:\n",
        "    action = [0, 1, 0]\n",
        "  elif num == 3:\n",
        "    action = [0, 0, 1]\n",
        "  else:\n",
        "    raise Exception()\n",
        "  \n",
        "  return action\n",
        "\n",
        "# Simplify image (B&W, round values)\n",
        "def process_image(img):\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  img = rgb2gray(img)\n",
        "  img = np.round(img/100)*50\n",
        "  return img\n",
        "\n",
        "# Save image\n",
        "def save_picture(img, round, i):\n",
        "  cv2.imwrite('/content/imgs/img_{}_{}.png'.format(round, i), img)\n",
        "\n",
        "env = gym.make(\"CarRacing-v2\")\n",
        "\n",
        "round = 0\n",
        "\n",
        "while True:\n",
        "  done = False\n",
        "  observation = env.reset()\n",
        "  i = 0\n",
        "  # Complete 200 steps\n",
        "  while not done and i<200:\n",
        "    action = env.action_space.sample() # Random action\n",
        "    action = format_action(action)\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    # Stack frames if multiple of 50\n",
        "    if i >= SAVE_FREQUENCY and i%SAVE_FREQUENCY == 0:\n",
        "      images = np.zeros((96, 96, 3))\n",
        "      images[:, :, 0] = process_image(observation)\n",
        "    elif i >= SAVE_FREQUENCY and i%SAVE_FREQUENCY == 1:\n",
        "      images[:, :, 1] = process_image(observation)\n",
        "    elif i >= SAVE_FREQUENCY and i%SAVE_FREQUENCY == 2:\n",
        "      # Save images if third frame\n",
        "      images[:, :, 2] = process_image(observation)\n",
        "      if random.random()<.5:\n",
        "        images = cv2.flip(images, 1)\n",
        "      save_picture(images, round, i)\n",
        "    i += 1\n",
        "  print('Done round {}'.format(round))\n",
        "  round += 1\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "VgX62Fo14IS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import cv2 and numpy\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "folder = \"\" # Images stored folder\n",
        "\n",
        "images = []\n",
        "\n",
        "# Loop through the files in the folder\n",
        "for file in sorted(os.listdir(folder)):\n",
        "    img = cv2.imread(folder + \"/\" + file)\n",
        "\n",
        "    images.append(img)\n",
        "\n",
        "images = np.array(images)\n",
        "\n",
        "images = images/150 # Normalizing\n",
        "print(images.shape)"
      ],
      "metadata": {
        "id": "pb9Wpjud4WPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "dv02SbKr4j6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from os import walk\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import Reshape, Flatten, Conv2D, Dense, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.optimizers import Adam, RMSprop, Adadelta"
      ],
      "metadata": {
        "id": "a5mHzT1o4q1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = keras.Input(shape=(96, 96, 3))\n",
        "\n",
        "x = Conv2D(16, (3, 3), padding='same', strides=2)(encoder_input)\n",
        "x = Conv2D(8, (3, 3), padding='same', strides=2)(x)\n",
        "x = Conv2D(4, (5, 5), padding='same', strides=2)(x)\n",
        "x = Conv2D(2, (5, 5), padding='same', strides=2)(x)\n",
        "x = Conv2D(1, (5, 5), padding='same')(x)\n",
        "\n",
        "x = Reshape((36,))(x)\n",
        "encoder_output = Dense(32, activation='sigmoid')(x)\n",
        "\n",
        "encoder = keras.Model(encoder_input, x)\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "KWPtQZef4lif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder_input = keras.Input(shape=(16,))\n",
        "\n",
        "decoder_output = Dense(32)(encoder_output)\n",
        "decoder_output = Dense(72)(decoder_output)\n",
        "decoder_output = Reshape((6, 6, 2))(decoder_output)\n",
        "decoder_output = Conv2DTranspose(2, (7, 7), padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2DTranspose(4, (5, 5), padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2DTranspose(8, (3, 3), padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2DTranspose(16, (3, 3), padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(decoder_output)\n",
        "\n",
        "# Define the decoder model object\n",
        "auto_encoder = keras.Model(encoder_input, decoder_output)\n",
        "\n",
        "# Define the auto-encoder model by combining the encoder and decoder\n",
        "auto_encoder.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "YMrdG9Gd4oXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_encoder.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=.01))\n",
        "# auto_encoder.compile(loss='mse', optimizer=Adadelta())\n",
        "\n",
        "auto_encoder.summary()"
      ],
      "metadata": {
        "id": "7D-NG8w34xfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_encoder.fit(\n",
        "    x=images,\n",
        "    y=images,\n",
        "    batch_size=32,\n",
        "    epochs=300,\n",
        "    verbose=\"auto\",\n",
        "    validation_split=0.2)"
      ],
      "metadata": {
        "id": "-R4V6e7r42l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "hWhAjymU45Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "test_image = cv2.imread('/content/imgs/img_132_102.png')\n",
        "cv2_imshow(test_image)\n",
        "test_image = np.reshape(test_image, (1, 96, 96, 3))/150"
      ],
      "metadata": {
        "id": "2QwEQ7Oe47Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = auto_encoder.predict(test_image)\n",
        "output = np.reshape(output, (96, 96, 3))*150\n",
        "cv2_imshow(output)"
      ],
      "metadata": {
        "id": "U9AbuuBQ47wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(np.clip(output[..., 0] - output[..., 2], 0, 10)*20)"
      ],
      "metadata": {
        "id": "7kzvZCBT7Lah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(np.clip(output[..., 0] - output[..., 2], -10, 0)*-20)"
      ],
      "metadata": {
        "id": "8vLCPyWJ7MvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Encoder"
      ],
      "metadata": {
        "id": "m2GOmDzf5lKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_encoder_input = keras.layers.Input((96, 96, 3))\n",
        "save_encoder = save_encoder_input\n",
        "for layer in auto_encoder.layers[1:8]:\n",
        "  print(layer, layer.name)\n",
        "  save_encoder = layer(save_encoder)\n",
        "\n",
        "save_encoder = keras.models.Model(inputs=save_encoder_input, outputs=save_encoder)\n",
        "save_encoder.summary()"
      ],
      "metadata": {
        "id": "8jWDgJz-5nSS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
